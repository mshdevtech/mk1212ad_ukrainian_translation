# This script merges translation files from a source directory (`_upstream/en/text/db`)
# with corresponding files in a target directory (`translation/text/db`).
# It performs the following steps:
#
# 1. Reads all `.loc.tsv` files from the source directory.
# 2. For each source file:
#    - Reads the corresponding target file if it exists, or creates an empty DataFrame.
#    - Filters out rows with empty or whitespace-only keys.
#    - Merges the source and target files on the `key` column:
#      - Keeps existing translations from the target file if they are non-empty.
#      - Copies the source text if no translation exists in the target file.
#    - Ensures the column order matches the source file and replaces NaN values with empty strings.
#    - Saves the merged file back to the target directory.
# 3. Tracks and logs statistics:
#    - Counts new keys added from the source file to the target file.
#    - Identifies and archives keys removed from the source file into an `obsolete` directory.
# 4. Outputs a summary of processed files, new keys added, and keys archived.
#
# Usage:
# - Place the source `.loc.tsv` files in `_upstream/en/text/db`.
# - Place the target `.loc.tsv` files (if any) in `translation/text/db`.
# - Run the script. The merged files will be saved in `translation/text/db`,
#   and removed keys will be archived in the `obsolete` directory.
import pandas as pd, pathlib, sys

SRC_DIR = pathlib.Path("_upstream/en/text/db")
TRG_DIR = pathlib.Path("translation/text/db")
OBS_DIR = pathlib.Path("obsolete")

# - stat counters -
files_done   = 0
total_added  = 0
total_removed = 0

# ‚îÄ‚îÄ –§—É–Ω–∫—Ü—ñ—ó –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def validate_tsv_file(file_path: pathlib.Path) -> tuple[bool, list[str]]:
    """–í–∞–ª—ñ–¥—É—î –æ–¥–∏–Ω TSV —Ñ–∞–π–ª —Ç–∞ –ø–æ–≤–µ—Ä—Ç–∞—î (is_valid, error_messages)."""
    errors = []
    try:
        df = pd.read_csv(file_path, sep="\t", dtype=str, keep_default_na=False)
    except Exception as e:
        errors.append(f"–Ω–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ —Ñ–∞–π–ª ({e})")
        return False, errors

    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫–æ–ª–æ–Ω–∫–∏
    required_cols = ["key", "text", "tooltip"]
    if list(df.columns) != required_cols:
        errors.append(f"–æ—á—ñ–∫—É–≤–∞–Ω–æ –∫–æ–ª–æ–Ω–∫–∏ {required_cols}, –∞ –æ—Ç—Ä–∏–º–∞–Ω–æ {list(df.columns)}")
        return False, errors

    # –ü–æ—Ä–æ–∂–Ω—ñ key
    empty_rows = df["key"].str.strip() == ""
    if empty_rows.any():
        rows = ", ".join(map(str, (df.index[empty_rows] + 2)))  # +2: header + 0-based
        errors.append(f"–ø–æ—Ä–æ–∂–Ω—ñ–π key —É —Ä—è–¥–∫–∞—Ö {rows}")

    # –î—É–±–ª—ñ–∫–∞—Ç–∏ key
    non_empty_keys = df.loc[~empty_rows, "key"]
    dup_keys = non_empty_keys[non_empty_keys.duplicated()]
    if not dup_keys.empty:
        keys = ", ".join(dup_keys.unique())
        errors.append(f"–¥—É–±–ª—ñ–∫–∞—Ç–∏ key: {keys}")

    return len(errors) == 0, errors

def validate_directory(dir_path: pathlib.Path, dir_name: str) -> tuple[bool, dict[str, list[str]]]:
    """–í–∞–ª—ñ–¥—É—î –≤—Å—ñ TSV —Ñ–∞–π–ª–∏ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó —Ç–∞ –ø–æ–≤–µ—Ä—Ç–∞—î (is_valid, file_errors)."""
    print(f"üîç –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ TSV —É {dir_name} ({dir_path})...")
    
    if not dir_path.exists():
        print(f"‚ö†Ô∏è  –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è {dir_name} –Ω–µ —ñ—Å–Ω—É—î")
        return True, {}
    
    file_errors = {}
    has_errors = False
    
    for file_path in sorted(dir_path.glob("*.loc.tsv")):
        is_valid, errors = validate_tsv_file(file_path)
        if errors:
            file_errors[file_path.name] = errors
            has_errors = True
            print(f"‚ùå {file_path.name}:")
            for error in errors:
                print(f"   ‚Ä¢ {error}")
        else:
            print(f"‚úÖ {file_path.name}")
    
    print()
    return not has_errors, file_errors

def ask_continue() -> bool:
    """–ü–∏—Ç–∞—î –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ —á–∏ –ø—Ä–æ–¥–æ–≤–∂—É–≤–∞—Ç–∏ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è."""
    while True:
        response = input("–ü—Ä–æ–¥–æ–≤–∂–∏—Ç–∏ –º–µ—Ä–¥–∂? (y/n): ").lower().strip()
        if response in ['y', 'yes', '—Ç–∞–∫', '—Ç']:
            return True
        elif response in ['n', 'no', '–Ω—ñ', '–Ω']:
            return False
        else:
            print("–ë—É–¥—å –ª–∞—Å–∫–∞, –≤–≤–µ–¥—ñ—Ç—å 'y' –∞–±–æ 'n'")

# ‚îÄ‚îÄ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ñ–∞–π–ª—ñ–≤ –ø–µ—Ä–µ–¥ –º–µ—Ä–¥–∂–µ–º ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
print("=== –ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–ê –ü–ï–†–ï–í–Ü–†–ö–ê –§–ê–ô–õ–Ü–í ===\n")

src_valid, src_errors = validate_directory(SRC_DIR, "SRC_DIR")
trg_valid, trg_errors = validate_directory(TRG_DIR, "TRG_DIR")

if not src_valid or not trg_valid:
    print("‚ö†Ô∏è  –ó–ù–ê–ô–î–ï–ù–û –ü–û–ú–ò–õ–ö–ò –í –§–ê–ô–õ–ê–•!")
    print("–°–∫—Ä–∏–ø—Ç –º–æ–∂–µ –≤—ñ–¥–ø—Ä–∞—Ü—é–≤–∞—Ç–∏ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–æ —ñ –∫—Ä–∞—â–µ –≤–∏–ø—Ä–∞–≤–∏—Ç–∏ –ø—Ä–æ–±–ª–µ–º–Ω—ñ —Ñ–∞–π–ª–∏ –≤–ª–∞—Å–Ω–æ—Ä—É—á.")
    print()
    
    if not ask_continue():
        print("–ú–µ—Ä–¥–∂ —Å–∫–∞—Å–æ–≤–∞–Ω–æ.")
        sys.exit(1)
    
    print("–ü—Ä–æ–¥–æ–≤–∂—É—î–º–æ –º–µ—Ä–¥–∂...\n")
else:
    print("‚úÖ –í—Å—ñ —Ñ–∞–π–ª–∏ –≤–∞–ª—ñ–¥–Ω—ñ, –ø—Ä–æ–¥–æ–≤–∂—É—î–º–æ –º–µ—Ä–¥–∂.\n")

print("=== –ü–û–ß–ò–ù–ê–Ñ–ú–û –ú–ï–†–î–ñ ===\n")

for src_path in SRC_DIR.glob("*.loc.tsv"):
    trg_path = TRG_DIR / src_path.name
    read = lambda p: pd.read_csv(
        p, sep="\t", dtype=str, keep_default_na=False, na_filter=False
    )

    src = read(src_path)
    trg = read(trg_path) if trg_path.exists() else pd.DataFrame(columns=src.columns)

    # - Filter empty keys -
    src = src[src["key"].str.strip() != ""].copy()
    trg = trg[trg["key"].str.strip() != ""].copy()

    # - Merging -
    merged = src.merge(trg, on="key", how="left", suffixes=("", "_old"))

    # 1) if translation already exist ‚Äî keep it
    # 2) if translation doesn't exist ‚Äî copy original text
    merged["text"] = merged["text_old"].where(
        merged["text_old"].notna() & (merged["text_old"] != ""),        # —è–∫—â–æ text_old –ù–ï NaN ‚Üí –∑–∞–ª–∏—à–∞—î–º–æ
        merged["text"]                     # —ñ–Ω–∞–∫—à–µ –±–µ—Ä–µ–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è –∑ text
    )

    merged = merged[src.columns]   # return column order

    # NaN ‚Üí ""
    merged = merged.fillna("")

    trg_path.parent.mkdir(parents=True, exist_ok=True)
    merged.to_csv(trg_path, sep="\t", index=False, na_rep="")

    # - statistic for new keys -
    new_keys = src.loc[~src["key"].isin(trg["key"])]
    total_added += len(new_keys)

    # -Ô∏é Removed keys -
    removed = trg.loc[~trg["key"].isin(src["key"])]
    if not removed.empty:
        OBS_DIR.mkdir(parents=True, exist_ok=True)
        removed.to_csv(OBS_DIR / src_path.name, sep="\t", index=False)
        total_removed += len(removed)

    files_done += 1
    print(f"‚úì {src_path.name}: +{len(new_keys)} new, -{len(removed)} removed")

print("\n=== Merge completed ===")
print(f"Processed files : {files_done}")
print(f"New keys added  : {total_added}")
print(f"Keys archived   : {total_removed}")
print("Done!")

sys.exit(0)